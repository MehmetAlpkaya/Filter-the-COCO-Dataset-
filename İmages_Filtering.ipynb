{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6eab0b4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\alpka\\anaconda3\\lib\\site-packages (2.9.1)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\alpka\\anaconda3\\lib\\site-packages (from tensorflow) (1.12.1)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\alpka\\anaconda3\\lib\\site-packages (from tensorflow) (1.2.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\alpka\\anaconda3\\lib\\site-packages (from tensorflow) (21.3)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\alpka\\anaconda3\\lib\\site-packages (from tensorflow) (14.0.6)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\alpka\\anaconda3\\lib\\site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in c:\\users\\alpka\\anaconda3\\lib\\site-packages (from tensorflow) (1.1.2)\n",
      "Requirement already satisfied: setuptools in c:\\users\\alpka\\anaconda3\\lib\\site-packages (from tensorflow) (61.2.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\alpka\\anaconda3\\lib\\site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: flatbuffers<2,>=1.12 in c:\\users\\alpka\\anaconda3\\lib\\site-packages (from tensorflow) (1.12)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\alpka\\anaconda3\\lib\\site-packages (from tensorflow) (0.26.0)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in c:\\users\\alpka\\anaconda3\\lib\\site-packages (from tensorflow) (0.4.0)\n",
      "Requirement already satisfied: tensorboard<2.10,>=2.9 in c:\\users\\alpka\\anaconda3\\lib\\site-packages (from tensorflow) (2.9.1)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\alpka\\anaconda3\\lib\\site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.10.0,>=2.9.0rc0 in c:\\users\\alpka\\anaconda3\\lib\\site-packages (from tensorflow) (2.9.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\alpka\\anaconda3\\lib\\site-packages (from tensorflow) (3.6.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\alpka\\anaconda3\\lib\\site-packages (from tensorflow) (1.42.0)\n",
      "Requirement already satisfied: numpy>=1.20 in c:\\users\\alpka\\anaconda3\\lib\\site-packages (from tensorflow) (1.21.5)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\alpka\\anaconda3\\lib\\site-packages (from tensorflow) (4.1.1)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\alpka\\anaconda3\\lib\\site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\alpka\\anaconda3\\lib\\site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in c:\\users\\alpka\\anaconda3\\lib\\site-packages (from tensorflow) (3.19.4)\n",
      "Requirement already satisfied: keras<2.10.0,>=2.9.0rc0 in c:\\users\\alpka\\anaconda3\\lib\\site-packages (from tensorflow) (2.9.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\alpka\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow) (0.37.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\alpka\\anaconda3\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow) (2.28.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\users\\alpka\\anaconda3\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\alpka\\anaconda3\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow) (2.0.3)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\alpka\\anaconda3\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow) (0.4.6)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\alpka\\anaconda3\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow) (3.3.4)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\alpka\\anaconda3\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow) (2.6.0)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\alpka\\anaconda3\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow) (1.8.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\alpka\\anaconda3\\lib\\site-packages (from packaging->tensorflow) (3.0.4)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\alpka\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\alpka\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (4.2.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\alpka\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (4.7.2)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\alpka\\anaconda3\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\alpka\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (2022.6.15)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\alpka\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\alpka\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (1.26.9)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\alpka\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (3.3)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\alpka\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\alpka\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow) (3.2.0)\n"
     ]
    }
   ],
   "source": [
    "! pip install tensorflow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "95c0ccb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycocotools.coco import COCO\n",
    "import numpy as np\n",
    "import skimage.io as io\n",
    "import random\n",
    "import os\n",
    "import cv2\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import glob\n",
    "import shutil\n",
    "\n",
    "## For visualizing results\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e22f51cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./COCOdataset2017/annotations/coco_annotation.json\n",
      "loading annotations into memory...\n",
      "Done (t=22.09s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "dataDir='./COCOdataset2017'\n",
    "dataType='train2017'\n",
    "annFile='{}/annotations/coco_annotation.json'.format(dataDir)\n",
    "print(annFile)\n",
    "# initialize the COCO api for instance annotations\n",
    "coco=COCO(annFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "41eaaa49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 COCO categories: \n",
      "person traffic light stop sign bench backpack umbrella handbag\n",
      "\n",
      "3 COCO supercategories: \n",
      "person outdoor accessory\n"
     ]
    }
   ],
   "source": [
    "# display COCO categories and supercategories\n",
    "catIDs = coco.getCatIds()\n",
    "cats = coco.loadCats(catIDs)\n",
    "\n",
    "nms=[cat['name'] for cat in cats]\n",
    "print(len(nms),'COCO categories: \\n{}\\n'.format(' '.join(nms)))\n",
    "\n",
    "nms = set([cat['supercategory'] for cat in cats])\n",
    "print(len(nms),'COCO supercategories: \\n{}'.format(' '.join(nms)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ce3f09b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'supercategory': 'person', 'id': 1, 'name': 'person'},\n",
       " {'supercategory': 'outdoor', 'id': 10, 'name': 'traffic light'},\n",
       " {'supercategory': 'outdoor', 'id': 13, 'name': 'stop sign'},\n",
       " {'supercategory': 'outdoor', 'id': 15, 'name': 'bench'},\n",
       " {'supercategory': 'accessory', 'id': 27, 'name': 'backpack'},\n",
       " {'supercategory': 'accessory', 'id': 28, 'name': 'umbrella'},\n",
       " {'supercategory': 'accessory', 'id': 31, 'name': 'handbag'}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Observe how the ids range from 0 to 90\n",
    "cats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b520f5e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e779c94a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a5d876a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bfa3969",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images containing the  without filter classes: 91895\n"
     ]
    }
   ],
   "source": [
    "# verilen kategorileri içeren tüm resimleri al, rastgele birini seç\n",
    "classes = ['person','traffic light','stop sign', 'bench','umbrella','handbag','backpack']\n",
    "\n",
    "images = []\n",
    "if classes!=None:\n",
    "    # listedeki her bir sınıf için yinele\n",
    "    for className in classes:\n",
    "        # verilen sınıfı içeren tüm resimleri al\n",
    "        catIds = coco.getCatIds(catNms=className)\n",
    "        imgIds = coco.getImgIds(catIds=catIds)\n",
    "        images += coco.loadImgs(imgIds)\n",
    "else:\n",
    "    imgIds = coco.getImgIds()\n",
    "    images = coco.loadImgs(imgIds)\n",
    "print(\"Number of images containing the  without filter classes:\", len(images))    \n",
    "# Şimdi, tekrarlanan görüntüleri filtrelenecek \n",
    "unique_images = []\n",
    "\n",
    "source=\"C:\\\\Users\\\\alpka\\\\Project_folder\\\\COCOdataset2017\\\\images\\\\train2017\\\\\"\n",
    "#shutil.copy(source, dst_dir)\n",
    "for i in range(len(images)):\n",
    "    if images[i] not in unique_images:\n",
    "        unique_images.append(images[i])\n",
    "        \n",
    "for i in range(len(unique_images)):\n",
    "    dst_dir=\"C:/Users/alpka/Project_folder/COCOdatasetNew/\"\n",
    "    shutil.copy(source+unique_images[i]['file_name'], dst_dir)\n",
    "print(unique_images[0]) \n",
    "img = coco.loadImgs(imgIds[np.random.randint(0,len(imgIds))])[0]\n",
    "I = io.imread('{}/images/{}/{}'.format(dataDir,dataType,img['file_name']))/255.0\n",
    "\n",
    "\n",
    "plt.imshow(I)\n",
    "plt.axis('off')\n",
    "\n",
    "dataset_size = len(unique_images)\n",
    "#000000532481\n",
    "#000000532491\n",
    "print(\"Number of images containing the filter classes:\", dataset_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93b9508d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(I); plt.axis('off')\n",
    "annIds = coco.getAnnIds(imgIds=img['id'], catIds=catIds, iscrowd=None)\n",
    "anns = coco.loadAnns(annIds)\n",
    "coco.showAnns(anns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c593d5bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "annFile = '{}/annotations/instances_{}.json'.format(folder, mode)\n",
    "coco = COCO(annFile)\n",
    "print(coco)\n",
    "images = []\n",
    "if classes!=None:\n",
    "     # listedeki her bir sınıf için yinele\n",
    "    for className in classes:\n",
    "         # verilen kategorileri içeren tüm resimleri al\n",
    "        catIds = coco.getCatIds(catNms=className)\n",
    "        imgIds = coco.getImgIds(catIds=catIds)\n",
    "        images += coco.loadImgs(imgIds)\n",
    "    \n",
    "else:\n",
    "    imgIds = coco.getImgIds()\n",
    "    images = coco.loadImgs(imgIds)\n",
    "    \n",
    "# Now, filter out the repeated images\n",
    "unique_images = []\n",
    "for i in range(len(images)):\n",
    "    if images[i] not in unique_images:\n",
    "        unique_images.append(images[i])\n",
    "            \n",
    "random.shuffle(unique_images)\n",
    "dataset_size = len(unique_images)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d53aae20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filterDataset(folder, classes=None, mode='train'):    \n",
    "    # initialize COCO api for instance annotations\n",
    "    annFile = '{}/annotations/instances_{}.json'.format(folder, mode)\n",
    "    coco = COCO(annFile)\n",
    "    print(coco)\n",
    "    images = []\n",
    "    if classes!=None:\n",
    "        # listedeki her bir sınıf için yinele\n",
    "        for className in classes:\n",
    "            # verilen kategorileri içeren tüm resimleri al\n",
    "            catIds = coco.getCatIds(catNms=className)\n",
    "            imgIds = coco.getImgIds(catIds=catIds)\n",
    "            images += coco.loadImgs(imgIds)\n",
    "    \n",
    "    else:\n",
    "        imgIds = coco.getImgIds()\n",
    "        images = coco.loadImgs(imgIds)\n",
    "    \n",
    "    # Now, filter out the repeated images\n",
    "    unique_images = []\n",
    "    for i in range(len(images)):\n",
    "        if images[i] not in unique_images:\n",
    "            unique_images.append(images[i])\n",
    "            \n",
    "    random.shuffle(unique_images)\n",
    "    dataset_size = len(unique_images)\n",
    "    \n",
    "    return unique_images, dataset_size, coco,annFile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5b8fe6b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.45s)\n",
      "creating index...\n",
      "index created!\n",
      "<pycocotools.coco.COCO object at 0x000001AE2F857EB0>\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [11]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m classes \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mperson\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtraffic light\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstop sign\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbench\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mumbrella\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhandbag\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbackpack\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m      3\u001b[0m mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval2017\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m----> 5\u001b[0m images, dataset_size, coco \u001b[38;5;241m=\u001b[39m filterDataset(folder, classes,  mode)\n\u001b[0;32m      6\u001b[0m I \u001b[38;5;241m=\u001b[39m io\u001b[38;5;241m.\u001b[39mimread(images[\u001b[38;5;241m100\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcoco_url\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(annFile[\u001b[38;5;241m0\u001b[39m])\n",
      "\u001b[1;31mValueError\u001b[0m: too many values to unpack (expected 3)"
     ]
    }
   ],
   "source": [
    "folder = './COCOdataset2017'\n",
    "classes = ['person','traffic light','stop sign', 'bench','umbrella','handbag','backpack']\n",
    "mode = 'val2017'\n",
    "\n",
    "images, dataset_size, coco = filterDataset(folder, classes,  mode)\n",
    "I = io.imread(images[100]['coco_url'])\n",
    "\n",
    "\n",
    "plt.imshow(I)\n",
    "plt.axis('off')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb62f3f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
